{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\nimport transformers\nimport datasets\nimport pandas as pd\nimport numpy as np\n\nmodel_checkpoint = \"/kaggle/input/huggingfacedebertav3variants/deberta-v3-xsmall\"\n\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-11T10:18:07.089996Z","iopub.execute_input":"2024-05-11T10:18:07.090395Z","iopub.status.idle":"2024-05-11T10:18:14.454873Z","shell.execute_reply.started":"2024-05-11T10:18:07.090364Z","shell.execute_reply":"2024-05-11T10:18:14.453829Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/llm-detect-ai-generated-text/sample_submission.csv\n/kaggle/input/llm-detect-ai-generated-text/train_prompts.csv\n/kaggle/input/llm-detect-ai-generated-text/test_essays.csv\n/kaggle/input/llm-detect-ai-generated-text/train_essays.csv\n/kaggle/input/huggingfacedebertav3variants/khalidalt-DeBERTa-v3-large/spm.model\n/kaggle/input/huggingfacedebertav3variants/khalidalt-DeBERTa-v3-large/config.json\n/kaggle/input/huggingfacedebertav3variants/khalidalt-DeBERTa-v3-large/README (1).md\n/kaggle/input/huggingfacedebertav3variants/khalidalt-DeBERTa-v3-large/README.md\n/kaggle/input/huggingfacedebertav3variants/khalidalt-DeBERTa-v3-large/tokenizer_config.json\n/kaggle/input/huggingfacedebertav3variants/khalidalt-DeBERTa-v3-large/tokenizer_config (1).json\n/kaggle/input/huggingfacedebertav3variants/khalidalt-DeBERTa-v3-large/pytorch_model.bin\n/kaggle/input/huggingfacedebertav3variants/khalidalt-DeBERTa-v3-large/special_tokens_map.json\n/kaggle/input/huggingfacedebertav3variants/khalidalt-DeBERTa-v3-large/gitattributes.txt\n/kaggle/input/huggingfacedebertav3variants/khalidalt-DeBERTa-v3-large/added_tokens.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-base-squad2/spm.model\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-base-squad2/config.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-base-squad2/README.md\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-base-squad2/tokenizer.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-base-squad2/tokenizer_config.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-base-squad2/pytorch_model.bin\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-base-squad2/special_tokens_map.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-base-squad2/gitattributes.txt\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-base-squad2/added_tokens.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-ontonotes5/spm.model\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-ontonotes5/config.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-ontonotes5/trainer_config.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-ontonotes5/README.md\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-ontonotes5/tokenizer.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-ontonotes5/tokenizer_config.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-ontonotes5/pytorch_model.bin\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-ontonotes5/special_tokens_map.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-ontonotes5/gitattributes.txt\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-ontonotes5/added_tokens.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-offensive/spm.model\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-offensive/run_test.sh\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-offensive/config.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-offensive/run_train.sh\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-offensive/trainer_state.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-offensive/eval_results.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-offensive/training_args.bin\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-offensive/README.md\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-offensive/tokenizer.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-offensive/all_results.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-offensive/tokenizer_config.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-offensive/pytorch_model.bin\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-offensive/special_tokens_map.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-offensive/gitattributes.txt\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-offensive/added_tokens.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large-offensive/test_results.json\n/kaggle/input/huggingfacedebertav3variants/yevheniimaslov-deberta-v3-base-cola/spm.model\n/kaggle/input/huggingfacedebertav3variants/yevheniimaslov-deberta-v3-base-cola/config.json\n/kaggle/input/huggingfacedebertav3variants/yevheniimaslov-deberta-v3-base-cola/trainer_state.json\n/kaggle/input/huggingfacedebertav3variants/yevheniimaslov-deberta-v3-base-cola/training_args.bin\n/kaggle/input/huggingfacedebertav3variants/yevheniimaslov-deberta-v3-base-cola/tokenizer.json\n/kaggle/input/huggingfacedebertav3variants/yevheniimaslov-deberta-v3-base-cola/tokenizer_config.json\n/kaggle/input/huggingfacedebertav3variants/yevheniimaslov-deberta-v3-base-cola/pytorch_model.bin\n/kaggle/input/huggingfacedebertav3variants/yevheniimaslov-deberta-v3-base-cola/scaler.pt\n/kaggle/input/huggingfacedebertav3variants/yevheniimaslov-deberta-v3-base-cola/scheduler.pt\n/kaggle/input/huggingfacedebertav3variants/yevheniimaslov-deberta-v3-base-cola/special_tokens_map.json\n/kaggle/input/huggingfacedebertav3variants/yevheniimaslov-deberta-v3-base-cola/optimizer.pt\n/kaggle/input/huggingfacedebertav3variants/yevheniimaslov-deberta-v3-base-cola/gitattributes.txt\n/kaggle/input/huggingfacedebertav3variants/yevheniimaslov-deberta-v3-base-cola/rng_state.pth\n/kaggle/input/huggingfacedebertav3variants/yevheniimaslov-deberta-v3-base-cola/added_tokens.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-base/rust_model.ot\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-base/spm.model\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-base/config.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-base/README.md\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-base/tf_model.h5\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-base/tokenizer_config.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-base/pytorch_model.bin\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-base/gitattributes.txt\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-xsmall/spm.model\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-xsmall/config.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-xsmall/pytorch_model.generator.bin\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-xsmall/README.md\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-xsmall/tf_model.h5\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-xsmall/tokenizer_config.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-xsmall/pytorch_model.bin\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-xsmall/generator_config.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-xsmall/gitattributes.txt\n/kaggle/input/huggingfacedebertav3variants/mdeberta-v3-base/spm.model\n/kaggle/input/huggingfacedebertav3variants/mdeberta-v3-base/config.json\n/kaggle/input/huggingfacedebertav3variants/mdeberta-v3-base/README.md\n/kaggle/input/huggingfacedebertav3variants/mdeberta-v3-base/tf_model.h5\n/kaggle/input/huggingfacedebertav3variants/mdeberta-v3-base/tokenizer_config.json\n/kaggle/input/huggingfacedebertav3variants/mdeberta-v3-base/pytorch_model.bin\n/kaggle/input/huggingfacedebertav3variants/mdeberta-v3-base/gitattributes.txt\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-small/spm.model\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-small/config.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-small/README.md\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-small/tf_model.h5\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-small/tokenizer_config.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-small/pytorch_model.bin\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-small/gitattributes.txt\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large/spm.model\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large/config.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large/README.md\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large/tf_model.h5\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large/tokenizer_config.json\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large/pytorch_model.bin\n/kaggle/input/huggingfacedebertav3variants/deberta-v3-large/gitattributes.txt\n/kaggle/input/daigt-v2-train-dataset/train_v2_drcat_02.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"from datasets import Dataset\n\n#from transformers import AutoModel\n#model = AutoModel.from_pretrained(\"microsoft/deberta-v3-xsmall\")","metadata":{"execution":{"iopub.status.busy":"2024-05-11T10:18:14.456852Z","iopub.execute_input":"2024-05-11T10:18:14.457398Z","iopub.status.idle":"2024-05-11T10:18:14.462240Z","shell.execute_reply.started":"2024-05-11T10:18:14.457367Z","shell.execute_reply":"2024-05-11T10:18:14.461048Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/daigt-v2-train-dataset/train_v2_drcat_02.csv')\ntrain = df[df.prompt_name != 'Car-free cities'].reset_index(drop=True)\nvalid = df[df.prompt_name == 'Car-free cities'].reset_index(drop=True)\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-11T10:18:14.463747Z","iopub.execute_input":"2024-05-11T10:18:14.464432Z","iopub.status.idle":"2024-05-11T10:18:16.773923Z","shell.execute_reply.started":"2024-05-11T10:18:14.464392Z","shell.execute_reply":"2024-05-11T10:18:16.772910Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                                                text  label  \\\n0  Phones\\n\\nModern humans today are always on th...      0   \n1  This essay will explain if drivers should or s...      0   \n2  Driving while the use of cellular devices\\n\\nT...      0   \n3  Phones & Driving\\n\\nDrivers should not be able...      0   \n4  Cell Phone Operation While Driving\\n\\nThe abil...      0   \n\n          prompt_name           source  RDizzl3_seven  \n0  Phones and driving  persuade_corpus          False  \n1  Phones and driving  persuade_corpus          False  \n2  Phones and driving  persuade_corpus          False  \n3  Phones and driving  persuade_corpus          False  \n4  Phones and driving  persuade_corpus          False  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n      <th>prompt_name</th>\n      <th>source</th>\n      <th>RDizzl3_seven</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Phones\\n\\nModern humans today are always on th...</td>\n      <td>0</td>\n      <td>Phones and driving</td>\n      <td>persuade_corpus</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>This essay will explain if drivers should or s...</td>\n      <td>0</td>\n      <td>Phones and driving</td>\n      <td>persuade_corpus</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Driving while the use of cellular devices\\n\\nT...</td>\n      <td>0</td>\n      <td>Phones and driving</td>\n      <td>persuade_corpus</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Phones &amp; Driving\\n\\nDrivers should not be able...</td>\n      <td>0</td>\n      <td>Phones and driving</td>\n      <td>persuade_corpus</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Cell Phone Operation While Driving\\n\\nThe abil...</td>\n      <td>0</td>\n      <td>Phones and driving</td>\n      <td>persuade_corpus</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train[\"source\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-05-11T10:18:16.776433Z","iopub.execute_input":"2024-05-11T10:18:16.776723Z","iopub.status.idle":"2024-05-11T10:18:16.794501Z","shell.execute_reply.started":"2024-05-11T10:18:16.776700Z","shell.execute_reply":"2024-05-11T10:18:16.793253Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"source\npersuade_corpus                       24037\nllama2_chat                            2411\nchat_gpt_moth                          2409\nmistral7binstruct_v1                   2408\nmistral7binstruct_v2                   2406\nllama_70b_v1                            984\ndarragh_claude_v6                       952\ndarragh_claude_v7                       951\nfalcon_180b_v1                          899\nkingki19_palm                           672\ntrain_essays                            670\ncohere-command                          301\npalm-text-bison1                        300\nradek_500                               250\nmistralai/Mistral-7B-Instruct-v0.1      201\nNousResearch/Llama-2-7b-chat-hf         200\nradekgpt4                               100\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"ds_train = Dataset.from_pandas(train)\nds_valid = Dataset.from_pandas(valid)\nds_train","metadata":{"execution":{"iopub.status.busy":"2024-05-11T10:18:16.796113Z","iopub.execute_input":"2024-05-11T10:18:16.796734Z","iopub.status.idle":"2024-05-11T10:18:17.797933Z","shell.execute_reply.started":"2024-05-11T10:18:16.796705Z","shell.execute_reply":"2024-05-11T10:18:17.796983Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['text', 'label', 'prompt_name', 'source', 'RDizzl3_seven'],\n    num_rows: 40151\n})"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-11T10:18:17.799332Z","iopub.execute_input":"2024-05-11T10:18:17.799643Z","iopub.status.idle":"2024-05-11T10:18:19.689042Z","shell.execute_reply.started":"2024-05-11T10:18:17.799611Z","shell.execute_reply":"2024-05-11T10:18:19.687938Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:550: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"def preprocess_function(examples):\n    return tokenizer(examples['text'], max_length=128, padding=True, truncation=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-11T10:18:19.690779Z","iopub.execute_input":"2024-05-11T10:18:19.691750Z","iopub.status.idle":"2024-05-11T10:18:19.696626Z","shell.execute_reply.started":"2024-05-11T10:18:19.691714Z","shell.execute_reply":"2024-05-11T10:18:19.695562Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"ds_train_enc = ds_train.map(preprocess_function, batched=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-11T10:18:19.697874Z","iopub.execute_input":"2024-05-11T10:18:19.698240Z","iopub.status.idle":"2024-05-11T10:18:50.766906Z","shell.execute_reply.started":"2024-05-11T10:18:19.698190Z","shell.execute_reply":"2024-05-11T10:18:50.765987Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/40151 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c7b034ec6984d1782634492675e4325"}},"metadata":{}}]},{"cell_type":"code","source":"ds_valid_enc = ds_valid.map(preprocess_function, batched=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-11T10:18:50.768192Z","iopub.execute_input":"2024-05-11T10:18:50.768645Z","iopub.status.idle":"2024-05-11T10:18:55.089450Z","shell.execute_reply.started":"2024-05-11T10:18:50.768608Z","shell.execute_reply":"2024-05-11T10:18:55.088491Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/4717 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f57bc883943542a89a4865fc8e2b8685"}},"metadata":{}}]},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n\nnum_labels = 2\nmodel = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=num_labels)","metadata":{"execution":{"iopub.status.busy":"2024-05-11T10:18:55.092330Z","iopub.execute_input":"2024-05-11T10:18:55.092696Z","iopub.status.idle":"2024-05-11T10:19:10.053974Z","shell.execute_reply.started":"2024-05-11T10:18:55.092670Z","shell.execute_reply":"2024-05-11T10:19:10.052902Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"2024-05-11 10:18:59.076085: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-11 10:18:59.076223: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-11 10:18:59.233316: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\nSome weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at /kaggle/input/huggingfacedebertav3variants/deberta-v3-xsmall and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"metric_name = \"roc_auc\"\nmodel_name = \"deberta-xsmall\"\ntrain_batch_size = 4\neval_batch_size = 32\ngrad_acc = 4","metadata":{"execution":{"iopub.status.busy":"2024-05-11T10:19:10.055348Z","iopub.execute_input":"2024-05-11T10:19:10.055995Z","iopub.status.idle":"2024-05-11T10:19:10.062846Z","shell.execute_reply.started":"2024-05-11T10:19:10.055963Z","shell.execute_reply":"2024-05-11T10:19:10.059970Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"num_steps = len(train) // (train_batch_size * grad_acc)\nnum_steps","metadata":{"execution":{"iopub.status.busy":"2024-05-11T10:19:10.063933Z","iopub.execute_input":"2024-05-11T10:19:10.064236Z","iopub.status.idle":"2024-05-11T10:19:10.098258Z","shell.execute_reply.started":"2024-05-11T10:19:10.064192Z","shell.execute_reply":"2024-05-11T10:19:10.097132Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"2509"},"metadata":{}}]},{"cell_type":"code","source":"args = TrainingArguments(\n    f\"{model_name}-finetuned\",\n    evaluation_strategy = \"steps\",\n    save_strategy = \"steps\",\n    eval_steps = num_steps // 3,\n    save_steps = num_steps // 3,\n    learning_rate=2e-5,\n    per_device_train_batch_size=train_batch_size,\n    per_device_eval_batch_size=eval_batch_size,\n    gradient_accumulation_steps=grad_acc,\n    num_train_epochs=1,\n    weight_decay=0.01,\n    load_best_model_at_end=False,\n    metric_for_best_model=metric_name,\n    report_to='none', # change to wandb after enabling internet access\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-11T10:19:10.099592Z","iopub.execute_input":"2024-05-11T10:19:10.099921Z","iopub.status.idle":"2024-05-11T10:19:10.220054Z","shell.execute_reply.started":"2024-05-11T10:19:10.099895Z","shell.execute_reply":"2024-05-11T10:19:10.219297Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\n\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    probs = np.exp(logits) / np.sum(np.exp(logits), axis=-1, keepdims=True)\n    auc = roc_auc_score(labels, probs[:,1], multi_class='ovr')\n    return {\"roc_auc\": auc}","metadata":{"execution":{"iopub.status.busy":"2024-05-11T10:19:10.221077Z","iopub.execute_input":"2024-05-11T10:19:10.221368Z","iopub.status.idle":"2024-05-11T10:19:10.227156Z","shell.execute_reply.started":"2024-05-11T10:19:10.221345Z","shell.execute_reply":"2024-05-11T10:19:10.226282Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer(\n    model,\n    args,\n    train_dataset=ds_train_enc,\n    eval_dataset=ds_valid_enc,\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-11T10:19:10.228350Z","iopub.execute_input":"2024-05-11T10:19:10.228678Z","iopub.status.idle":"2024-05-11T10:19:10.512603Z","shell.execute_reply.started":"2024-05-11T10:19:10.228648Z","shell.execute_reply":"2024-05-11T10:19:10.511610Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \ndataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-05-11T10:19:10.513975Z","iopub.execute_input":"2024-05-11T10:19:10.514308Z","iopub.status.idle":"2024-05-11T10:34:27.489839Z","shell.execute_reply.started":"2024-05-11T10:19:10.514282Z","shell.execute_reply":"2024-05-11T10:34:27.488974Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1254' max='1254' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1254/1254 15:12, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Roc Auc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>836</td>\n      <td>0.113400</td>\n      <td>0.105583</td>\n      <td>0.999544</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1254, training_loss=0.06341442575104879, metrics={'train_runtime': 916.6882, 'train_samples_per_second': 43.8, 'train_steps_per_second': 1.368, 'total_flos': 660858896941056.0, 'train_loss': 0.06341442575104879, 'epoch': 1.0})"},"metadata":{}}]},{"cell_type":"code","source":"test = pd.read_csv('/kaggle/input/llm-detect-ai-generated-text/test_essays.csv')\ntest_ds = Dataset.from_pandas(test)\ntest_ds_enc = test_ds.map(preprocess_function, batched=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-11T10:37:04.667176Z","iopub.execute_input":"2024-05-11T10:37:04.668154Z","iopub.status.idle":"2024-05-11T10:37:04.749662Z","shell.execute_reply.started":"2024-05-11T10:37:04.668111Z","shell.execute_reply":"2024-05-11T10:37:04.748672Z"},"trusted":true},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"496f7bf6fba249dcb2add283b8b13e90"}},"metadata":{}}]},{"cell_type":"code","source":"test_preds = trainer.predict(test_ds_enc)","metadata":{"execution":{"iopub.status.busy":"2024-05-11T10:37:10.035110Z","iopub.execute_input":"2024-05-11T10:37:10.035965Z","iopub.status.idle":"2024-05-11T10:37:10.163931Z","shell.execute_reply.started":"2024-05-11T10:37:10.035932Z","shell.execute_reply":"2024-05-11T10:37:10.162916Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}}]},{"cell_type":"code","source":"logits = test_preds.predictions\nprobs = np.exp(logits) / np.sum(np.exp(logits), axis=-1, keepdims=True)\nsub = pd.DataFrame()\nsub['id'] = test['id']\nsub['generated'] = probs[:,1]\nsub.to_csv('submission.csv', index=False)\nsub.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-11T10:37:14.194647Z","iopub.execute_input":"2024-05-11T10:37:14.195347Z","iopub.status.idle":"2024-05-11T10:37:14.218136Z","shell.execute_reply.started":"2024-05-11T10:37:14.195313Z","shell.execute_reply":"2024-05-11T10:37:14.217014Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"         id  generated\n0  0000aaaa   0.030469\n1  1111bbbb   0.991596\n2  2222cccc   0.957312","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>generated</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0000aaaa</td>\n      <td>0.030469</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1111bbbb</td>\n      <td>0.991596</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2222cccc</td>\n      <td>0.957312</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"res = []\nfor src in valid.source.unique():\n    if src in ['train_essays', 'persuade_corpus', 'original_moth']: continue\n    test2  = valid[valid['source'].isin([src, 'train_essays'])]\n    test_ds2 = Dataset.from_pandas(test2)\n    test_ds_enc2 = test_ds2.map(preprocess_function, batched=True)\n    eval_result = trainer.evaluate(test_ds_enc2)\n    score = eval_result['eval_roc_auc']\n    res.append(f'{src}: {score}')\n    \nfor r in res: print(r)","metadata":{"execution":{"iopub.status.busy":"2024-05-11T10:37:25.051655Z","iopub.execute_input":"2024-05-11T10:37:25.052114Z","iopub.status.idle":"2024-05-11T10:38:09.606589Z","shell.execute_reply.started":"2024-05-11T10:37:25.052083Z","shell.execute_reply":"2024-05-11T10:38:09.605562Z"},"trusted":true},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/723 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"abc6e2d01f1b438e9272ee8de2c55e54"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='205' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [12/12 00:43]\n    </div>\n    "},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/896 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1578d3fcbce24d9cac348a76838b7d5b"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/757 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a89863c4034482dab9b879fe1437579"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/958 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b64d2671f707449aa40d597e7e73c582"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/756 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fde50e2f9260455bb59e8ce31b5c9755"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/864 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18ed1a53453a40488bb6eb32ddb8d9ee"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/721 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73970f7f58f940a59db11759ea43ef1f"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/720 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3aa739249fc64c628038972ff340a6c4"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/718 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72b01365bceb4736932537dcb221b030"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/908 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a5b3e5d19fe546babf808fb03a6b9064"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/907 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7934da3f4ad147abb2b3d4f3720c7b51"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/757 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"02faf6bf78bd4d8da7bc97a9c2ea9500"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/757 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"10c2674d07c04e889076318dd74fb36c"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/808 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d4189bb98c3547f080974761ba4c2346"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1420 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9a7a88a4a2d41f595e2aa0dd4b1776c"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"name":"stdout","text":"mistral7binstruct_v2: 0.9736562942008486\nllama_70b_v1: 0.9957716860121386\ndarragh_claude_v7: 0.9915700141442716\nradek_500: 0.998320719949058\ndarragh_claude_v6: 0.9913979736166036\nfalcon_180b_v1: 0.9963783457508626\nmistral7binstruct_v1: 0.9698929076581128\nchat_gpt_moth: 0.9675769774779677\nllama2_chat: 0.9609103767519609\nNousResearch/Llama-2-7b-chat-hf: 0.9970233697143702\nmistralai/Mistral-7B-Instruct-v0.1: 0.997871287128713\npalm-text-bison1: 0.9915700141442716\ncohere-command: 0.9912588401697313\nradekgpt4: 0.9952105535871834\nkingki19_palm: 0.9994088368965127\n","output_type":"stream"}]},{"cell_type":"code","source":"import shutil\nshutil.make_archive('deberta_fine_tuned', 'zip', '/kaggle/working/deberta-xsmall-finetuned')","metadata":{"execution":{"iopub.status.busy":"2024-05-11T10:54:24.074043Z","iopub.execute_input":"2024-05-11T10:54:24.074997Z","iopub.status.idle":"2024-05-11T10:55:19.185455Z","shell.execute_reply.started":"2024-05-11T10:54:24.074954Z","shell.execute_reply":"2024-05-11T10:55:19.184493Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/deberta_fine_tuned.zip'"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}